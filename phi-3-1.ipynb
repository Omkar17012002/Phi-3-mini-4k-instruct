{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9257231,"sourceType":"datasetVersion","datasetId":5600934}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install bitsandbytes\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-30T08:27:21.504179Z","iopub.execute_input":"2024-08-30T08:27:21.504529Z","iopub.status.idle":"2024-08-30T08:27:42.348024Z","shell.execute_reply.started":"2024-08-30T08:27:21.504486Z","shell.execute_reply":"2024-08-30T08:27:42.346783Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig \n\n\nquantization_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n  #  bnb_4bit_quant_type=\"nf4\",\n   # bnb_4bit_compute_dtype=\"float16\",\n    #bnb_4bit_use_double_quant=True\n)\n\n\ntorch.random.manual_seed(0)\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"microsoft/Phi-3-mini-4k-instruct\",\n    device_map=\"cuda\",\n    quantization_config=quantization_config,\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n)\n\ngeneration_args = {\n    \"max_new_tokens\": 500,\n    \"return_full_text\": False,\n    \"temperature\": 0.0,\n    \"do_sample\": False,\n}\n\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-30T08:30:38.934031Z","iopub.execute_input":"2024-08-30T08:30:38.934515Z","iopub.status.idle":"2024-08-30T08:30:46.864458Z","shell.execute_reply.started":"2024-08-30T08:30:38.934474Z","shell.execute_reply":"2024-08-30T08:30:46.863597Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a1109a516e34ef592841b6aea819d65"}},"metadata":{}}]},{"cell_type":"code","source":"messages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n    {\"role\": \"user\", \"content\": \"give me the capital of india \"},\n   # {\"role\": \"user\", \"content\": logo('/kaggle/input/images/train_logo_146.png')}\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:31:41.542518Z","iopub.execute_input":"2024-08-30T08:31:41.542890Z","iopub.status.idle":"2024-08-30T08:31:41.547808Z","shell.execute_reply.started":"2024-08-30T08:31:41.542855Z","shell.execute_reply":"2024-08-30T08:31:41.546761Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\ndef logo(image_path):\n    return Image(filename=image_path)\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n    {\"role\": \"user\", \"content\": \"company name \"},\n   # {\"role\": \"user\", \"content\": logo('/kaggle/input/images/train_logo_146.png')}\n]\n\noutput = pipe(messages, **generation_args)\nprint(output[0]['generated_text'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}